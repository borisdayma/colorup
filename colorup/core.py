# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).

__all__ = ['PILImageLAB', 'RGBToLAB', 'TensorLAB', 'decodes', 'TensorL', 'TensorAB', 'Tuple_L_AB', 'Split_L_AB',
           'AdjustType']

# Cell
from fastai2.vision.all import *
import PIL.ImageCms

# Cell
class PILImageLAB(PILImage):
    '''PILImage in the LAB space'''
    def show(self, **kwargs):
        return super(PILImageLAB, RGBToLAB().decode(self)).show(**kwargs)

# Cell
class RGBToLAB(Transform):
    '''Convert a PILImage from RGB to LAB space'''
    order = ToTensor.order - 1  # perform before ToTensor
    rgb_profile = PIL.ImageCms.createProfile("sRGB")
    lab_profile  = PIL.ImageCms.createProfile("LAB")
    transform_rgb2lab = PIL.ImageCms.buildTransform(
        inputProfile=rgb_profile, outputProfile=lab_profile, inMode='RGB', outMode='LAB')
    transform_lab2rgb = PIL.ImageCms.buildTransform(
        inputProfile=lab_profile, outputProfile=rgb_profile, inMode='LAB', outMode='RGB')

    def encodes(self, x):
        return PILImageLAB(PIL.ImageCms.applyTransform(x, self.transform_rgb2lab))

    def decodes(self, x):
        return PILImage(PIL.ImageCms.applyTransform(x, self.transform_lab2rgb))

# Cell
class TensorLAB(TensorImage):
    '''Tensor for images in the LAB space'''
    makeDisplayTensor = noop

    def show(self, **kwargs):
        displayTensor = self.makeDisplayTensor()
        pilImageLAB = ToTensor().decode(displayTensor)
        return pilImageLAB.show(**kwargs)

# Add conversion to/from tensors
PILImageLAB._tensor_cls = TensorLAB  # used by `encodes`

@ToTensor
def decodes(self, o:TensorLAB): return PILImageLAB(Image.fromarray(np.uint8(o.permute(1,2,0)), mode='LAB'))

# Cell
class TensorL(TensorLAB):
    '''Tensor containing the L channel of an image'''
    def makeDisplayTensor(self):
        blank_channel = torch.zeros_like(self[0])
        return TensorLAB(torch.stack((self[0], blank_channel, blank_channel), dim=0))

# Cell
class TensorAB(TensorLAB):
    '''Tensor containing A & B channels of an image'''
    def makeDisplayTensor(self):
        '''juxtapose both channels'''
        blank_channel = torch.zeros_like(self[0])
        l_channel = torch.full_like(self[0], 128)
        img_A = torch.stack((l_channel, self[0], blank_channel), dim=0)
        img_B = torch.stack((l_channel, blank_channel, self[1]), dim=0)
        return TensorLAB(torch.cat((img_A, img_B), dim=2))

# Cell
class Tuple_L_AB(Tuple):
    '''Tuple with L channel and A & B channels'''
    def __new__(cls, x=None, *rest):
        '''Ensure each element is converted to correct type'''
        x = TensorL(x[0]), TensorAB(x[1])
        return super().__new__(cls, x)
    def makeDisplayTensor(self):
        img_L, img_AB = self
        return TensorLAB(torch.cat((img_L, img_AB), dim=0))

# Cell
class Split_L_AB(ItemTransform):
    '''Split TensorLAB into TensorL (input) & TensorAB (output)'''
    order = ToTensor.order + 1  # perform after ToTensor
    def encodes(self, x):
        return Tuple_L_AB((TensorL(x[0][None]), TensorAB(x[1:])))
    def decodes(self, x):
        return Tuple_L_AB(x).makeDisplayTensor()

# Cell
class AdjustType(Transform):
    '''Cast A & B channels to correct type to have continuous values'''
    order = Split_L_AB.order + 1
    def encodes(self, x:(TensorAB)):
        return x.char()
    def decodes(self, x:(TensorAB)):
        return x.byte()