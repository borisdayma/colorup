{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.vision.gan import *\n",
    "from fastai2.vision.gan import _conv, _conv_args, DenseResBlock\n",
    "from colorup.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner\n",
    "\n",
    "> Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a GAN to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of resized images\n",
    "img_size = 192\n",
    "\n",
    "# hyper-parameters\n",
    "aug_size = 92\n",
    "batch_size = 20\n",
    "partial_n = 2048 * 2  # to define one epoch\n",
    "samples_per_update = batch_size * 1  # for gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "path = Path('../data')\n",
    "items = get_image_files(path, folders=[f'train_{img_size}', f'valid_{img_size}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "augment_tfms = aug_transforms(size=aug_size, min_scale=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "dsrc = TfmdLists(items, tfms=[PILImage.create, Resize(img_size), RGBToLAB(), ToTensor(), Split_L_AB()], splits=FuncSplitter(lambda o:'valid' in str(o.parent))(items))\n",
    "dls = dsrc.partial_dataloaders(bs=batch_size, partial_n=partial_n, after_batch=[AdjustType(), IntToFloatTensor(), *augment_tfms, Normalize.from_stats(mean=[0.5],std=[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats\n",
    "print(f'Number of images in training set: {len(dsrc.train)}')\n",
    "print(f'Number of images in validation set: {len(dsrc.valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = unet_config(y_range=(-0.5,0.5), self_attention=True)\n",
    "generator = unet_learner(dls=dls, arch=resnet34, n_in=1, n_out=2, config=config, loss_func=MSELossFlat(), pretrained=False, cbs=[SaveModelCallback(fname='generator', with_opt=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_critic(n_channels=3, nf=128, n_blocks=3, p=0.15):\n",
    "    \"Critic to train a `GAN`.\"\n",
    "    layers = [\n",
    "        _conv(n_channels, nf, ks=4, stride=2),\n",
    "        nn.Dropout2d(p/2),\n",
    "        DenseResBlock(nf, **_conv_args)]\n",
    "    nf *= 2 # after dense block\n",
    "    for i in range(n_blocks):\n",
    "        layers += [\n",
    "            nn.Dropout2d(p),\n",
    "            _conv(nf, nf*2, ks=4, stride=2, self_attention=(i==0))]\n",
    "        nf *= 2\n",
    "    layers += [\n",
    "        ConvLayer(nf, 1, ks=4, bias=False, padding=0, norm_type=NormType.Spectral, act_cls=None),\n",
    "        nn.AdaptiveAvgPool2d(1)]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Learner(dls, gan_critic(nf=64), metrics=accuracy_multi, loss_func=BCEWithLogitsLossFlat(), cbs=[SaveModelCallback(fname='critic', with_opt=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def begin_batch(self: GANTrainer):\n",
    "    \"Clamp the weights with `self.clip` if it's not None, set the correct input/target.\"\n",
    "    if self.training and self.clip is not None:\n",
    "        for p in self.critic.parameters(): p.data.clamp_(-self.clip, self.clip)\n",
    "    if not self.gen_mode:\n",
    "        self.learn.xb, self.learn.yb = (torch.cat((*self.xb, *self.yb), dim=1),), self.xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss_from_critic(loss_crit):\n",
    "    \"Define loss functions for a GAN from `loss_crit`\"\n",
    "    def _loss_G(fake_pred):\n",
    "        ones = fake_pred.new_ones(fake_pred.shape[0])\n",
    "        return loss_crit(fake_pred, ones)\n",
    "\n",
    "    def _loss_C(real_pred, fake_pred):\n",
    "        # check we have same size of inputs\n",
    "        ones  = real_pred.new_ones (real_pred.shape[0])\n",
    "        zeros = fake_pred.new_zeros(fake_pred.shape[0])\n",
    "        return (loss_crit(real_pred, ones) + loss_crit(fake_pred, zeros)) / 2\n",
    "\n",
    "    return _loss_G, _loss_C    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(GANModule):\n",
    "    \"Wrapper around `crit_loss_func` and `gen_loss_func`\"\n",
    "    def __init__(self, gen_loss_func, crit_loss_func, gan_model, learn):\n",
    "        super().__init__()\n",
    "        store_attr(self, 'gen_loss_func,crit_loss_func,gan_model,learn')\n",
    "\n",
    "    def generator(self, output, target):\n",
    "        \"Evaluate the `output` with the critic then uses `self.gen_loss_func`\"\n",
    "        img_gen = torch.cat((*self.learn.xb, output), dim=1)\n",
    "        fake_pred = self.gan_model.critic(img_gen)\n",
    "        self.gen_loss = self.gen_loss_func(fake_pred)\n",
    "        return self.gen_loss\n",
    "\n",
    "    def critic(self, real_pred, input):\n",
    "        \"Create some `fake_pred` with the generator from `input` and compare them to `real_pred` in `self.crit_loss_func`.\"\n",
    "        fake = self.gan_model.generator(input).requires_grad_(False)\n",
    "        img_gen = torch.cat((input, fake), dim=1)\n",
    "        fake_pred = self.gan_model.critic(img_gen)\n",
    "        self.crit_loss = self.crit_loss_func(real_pred, fake_pred)\n",
    "        return self.crit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class GANLearner(Learner):\n",
    "    \"A `Learner` suitable for GANs.\"\n",
    "    def __init__(self, dls, generator, critic, gen_loss_func, crit_loss_func, switcher=None, gen_first=False,\n",
    "                 switch_eval=True, show_img=True, clip=None, cbs=None, metrics=None, **kwargs):\n",
    "        gan = GANModule(generator, critic)\n",
    "        loss_func = GANLoss(gen_loss_func, crit_loss_func, gan, self)\n",
    "        if switcher is None: switcher = FixedGANSwitcher(n_crit=5, n_gen=1)\n",
    "        trainer = GANTrainer(clip=clip, switch_eval=switch_eval, show_img=show_img)\n",
    "        cbs = L(cbs) + L(trainer, switcher)\n",
    "        metrics = L(metrics) + L(*LossMetrics('gen_loss,crit_loss'))\n",
    "        super().__init__(dls, gan, loss_func=loss_func, cbs=cbs, metrics=metrics, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_learners(cls, gen_learn, crit_learn, switcher=None, **kwargs):\n",
    "        \"Create a GAN from `learn_gen` and `learn_crit`.\"\n",
    "        losses = gan_loss_from_critic(crit_learn.loss_func)\n",
    "        return cls(gen_learn.dls, gen_learn.model, crit_learn.model, *losses, switcher=switcher, **kwargs)\n",
    "\n",
    "GANLearner.from_learners = delegates(to=GANLearner.__init__)(GANLearner.from_learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switcher = AdaptiveGANSwitcher(critic_thresh=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = GANLearner.from_learners(generator, critic, switcher=switcher, opt_func=partial(Adam, mom=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
