{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *\n",
    "import PIL.ImageCms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Basic functions for ColorUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Space Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are typically encoded in the RGB space. However, other color spaces have been developped for different purposes.\n",
    "\n",
    "We want to predict a colorized picture from a black & white version. Some color spaces have one of their channels corresponding to black & white, which is convenient as we then have to predict only 2 channels.\n",
    "\n",
    "In order to define our neural network and loss, we would like to use a color space where the difference between two colors is more closely related to visual perception. The [CIELAB color space](https://en.wikipedia.org/wiki/CIELAB_color_space) was developped for this purpose and has one of his channel corresponding directly to the black & white version.\n",
    "\n",
    "*Note: some more recent color spaces have been developed such as [CIECAM02](https://en.wikipedia.org/wiki/CIECAM02) to improve the correlation with visual perception. However we currently rely on [Pillow](https://github.com/python-pillow/Pillow) which does not handle these color space transformations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PILImageLAB(PILImage):\n",
    "    '''PILImage in the LAB space'''\n",
    "    def show(self, **kwargs):\n",
    "        return super(PILImageLAB, RGBToLAB().decode(self)).show(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RGBToLAB(Transform):\n",
    "    '''Convert a PILImage from RGB to LAB space'''\n",
    "    order = ToTensor.order - 1  # perform before ToTensor\n",
    "    rgb_profile = PIL.ImageCms.createProfile(\"sRGB\")\n",
    "    lab_profile  = PIL.ImageCms.createProfile(\"LAB\")\n",
    "    transform_rgb2lab = PIL.ImageCms.buildTransform(\n",
    "        inputProfile=rgb_profile, outputProfile=lab_profile, inMode='RGB', outMode='LAB')\n",
    "    transform_lab2rgb = PIL.ImageCms.buildTransform(\n",
    "        inputProfile=lab_profile, outputProfile=rgb_profile, inMode='LAB', outMode='RGB')\n",
    "\n",
    "    def encodes(self, x):\n",
    "        return PILImageLAB(PIL.ImageCms.applyTransform(x, self.transform_rgb2lab))\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return PILImage(PIL.ImageCms.applyTransform(x, self.transform_lab2rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorLAB(TensorImage):\n",
    "    '''Tensor for images in the LAB space'''\n",
    "    makeDisplayTensor = noop\n",
    "    \n",
    "    def show(self, **kwargs):\n",
    "        displayTensor = self.makeDisplayTensor()\n",
    "        pilImageLAB = ToTensor().decode(displayTensor)\n",
    "        return pilImageLAB.show(**kwargs)\n",
    "\n",
    "# Add conversion to/from tensors\n",
    "PILImageLAB._tensor_cls = TensorLAB  # used by `encodes`\n",
    "\n",
    "@ToTensor\n",
    "def decodes(self, o:TensorLAB): return PILImageLAB(Image.fromarray(np.uint8(o.permute(1,2,0)), mode='LAB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorL(TensorLAB):\n",
    "    '''Tensor containing the L channel of an image'''\n",
    "    def makeDisplayTensor(self):\n",
    "        blank_channel = torch.zeros_like(self[0])\n",
    "        return TensorLAB(torch.stack((self[0], blank_channel, blank_channel), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorAB(TensorLAB):\n",
    "    '''Tensor containing A & B channels of an image'''\n",
    "    def makeDisplayTensor(self):\n",
    "        '''juxtapose both channels'''\n",
    "        blank_channel = torch.zeros_like(self[0])\n",
    "        l_channel = torch.full_like(self[0], 128)\n",
    "        img_A = torch.stack((l_channel, self[0], blank_channel), dim=0)\n",
    "        img_B = torch.stack((l_channel, blank_channel, self[1]), dim=0)\n",
    "        return TensorLAB(torch.cat((img_A, img_B), dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tuple_L_AB(Tuple):\n",
    "    '''Tuple with L channel and A & B channels'''\n",
    "    def __new__(cls, x=None, *rest):\n",
    "        '''Ensure each element is converted to correct type'''        \n",
    "        x = TensorL(x[0]), TensorAB(x[1])\n",
    "        return super().__new__(cls, x)\n",
    "    def makeDisplayTensor(self):\n",
    "        img_L, img_AB = self\n",
    "        return TensorLAB(torch.cat((img_L, img_AB), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Split_L_AB(ItemTransform):\n",
    "    '''Split TensorLAB into TensorL (input) & TensorAB (output)'''\n",
    "    order = ToTensor.order + 1  # perform after ToTensor    \n",
    "    def encodes(self, x):\n",
    "        return Tuple_L_AB((TensorL(x[0][None]), TensorAB(x[1:])))    \n",
    "    def decodes(self, x):\n",
    "        return Tuple_L_AB(x).makeDisplayTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdjustType(Transform):\n",
    "    '''Cast A & B channels to correct type to have continuous values'''\n",
    "    order = Split_L_AB.order + 1    \n",
    "    def encodes(self, x:(TensorAB)):\n",
    "        return x.char()\n",
    "    def decodes(self, x:(TensorAB)):\n",
    "        return x.byte()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A & B channels are in the [0, 255] range, 0 being the neutral value.\n",
    "\n",
    "However, a few tests show that 127 & 128 are the two extrema so we use `AdjustType` to recast to [-128, 127] range with those two values as extrema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@IntToFloatTensor\n",
    "def encodes(self, o:TensorLAB):\n",
    "    return o.float().div_(255.)\n",
    "\n",
    "@IntToFloatTensor\n",
    "def decodes(self, o:TensorAB):\n",
    "    return o.mul_(255.).clamp(-128., 127.).char()\n",
    "\n",
    "@IntToFloatTensor\n",
    "def decodes(self, o:TensorL):\n",
    "    return o.clamp(0., 1.).mul_(255.).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Normalize\n",
    "def encodes(self, x:TensorAB): return x\n",
    "\n",
    "@Normalize\n",
    "def decodes(self, x:TensorAB): return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize only the input channel `TensorL` since the output `TensorAB` is already in [-0.5,0.5] range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
